{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ad508",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa soundfile awscli boto3\n",
    "\n",
    "print(\"‚úÖ All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd731bd",
   "metadata": {},
   "source": [
    "## 2. Configure AWS S3 Access\n",
    "\n",
    "**Add secrets in Kaggle:**\n",
    "1. Settings ‚Üí Add-ons ‚Üí Secrets\n",
    "2. Add: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b67665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Load AWS credentials from Kaggle Secrets\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = user_secrets.get_secret('AWS_ACCESS_KEY_ID')\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = user_secrets.get_secret('AWS_SECRET_ACCESS_KEY')\n",
    "    os.environ['AWS_DEFAULT_REGION'] = user_secrets.get_secret('AWS_REGION')\n",
    "    print(\"‚úÖ AWS credentials loaded from Kaggle secrets\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Kaggle secrets not found. Add them in Settings ‚Üí Secrets\")\n",
    "    raise\n",
    "\n",
    "# Verify AWS access\n",
    "!aws s3 ls s3://alertreck/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc9fba",
   "metadata": {},
   "source": [
    "## 3. Download Preprocessed Data from S3\n",
    "\n",
    "**Note:** With 30GB RAM, we can download the FULL dataset directly - no chunking needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fa4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working directory\n",
    "!mkdir -p /kaggle/working/preprocessed_data\n",
    "!mkdir -p /kaggle/working/train_chunks\n",
    "\n",
    "S3_BUCKET = \"alertreck\"\n",
    "DATA_DIR = \"/kaggle/working/preprocessed_data\"\n",
    "\n",
    "print(\"üì• Downloading preprocessed data from S3...\")\n",
    "print(\"‚ö†Ô∏è  Using chunked training data to avoid Kaggle's 20GB disk limit\")\n",
    "print(\"Files: train_chunks (10x ~2GB), val_data.pkl (960MB), test_data.pkl (1.1GB)\")\n",
    "print(\"‚è∞ This may take 10-15 minutes depending on connection speed.\\n\")\n",
    "\n",
    "# Download chunked training data (saves disk space!)\n",
    "print(\"Downloading training chunks...\")\n",
    "!aws s3 sync s3://{S3_BUCKET}/preprocessed_data/train_chunks/ /kaggle/working/train_chunks/\n",
    "\n",
    "# Download val, test, and config\n",
    "print(\"\\nDownloading validation and test data...\")\n",
    "!aws s3 cp s3://{S3_BUCKET}/preprocessed_data/val_data.pkl {DATA_DIR}/val_data.pkl\n",
    "!aws s3 cp s3://{S3_BUCKET}/preprocessed_data/test_data.pkl {DATA_DIR}/test_data.pkl\n",
    "!aws s3 cp s3://{S3_BUCKET}/preprocessed_data/preprocessing_config.json {DATA_DIR}/preprocessing_config.json\n",
    "\n",
    "print(\"\\n‚úÖ All data downloaded!\")\n",
    "\n",
    "# Verify downloads\n",
    "print(\"\\nüìÅ Downloaded files:\")\n",
    "!ls -lh {DATA_DIR}\n",
    "\n",
    "# Load configuration\n",
    "import json\n",
    "with open(f'{DATA_DIR}/preprocessing_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "print(f\"  Total files processed: {config['dataset_stats']['total_files']:,}\")\n",
    "print(f\"  Training samples: {config['dataset_stats']['train_size']:,}\")\n",
    "print(f\"  Validation samples: {config['dataset_stats']['val_size']:,}\")\n",
    "print(f\"  Test samples: {config['dataset_stats']['test_size']:,}\")\n",
    "print(f\"\\nüéµ Audio Configuration:\")\n",
    "print(f\"  Sample rate: {config['target_sr']} Hz\")\n",
    "print(f\"  Duration: {config['duration']} seconds\")\n",
    "print(f\"  Mel bands: {config['n_mels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a78c6b",
   "metadata": {},
   "source": [
    "## 4. Load Data into Memory\n",
    "\n",
    "**Kaggle Advantage:** With 30GB RAM, we load everything at once - much simpler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e96028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "print(\"üìÇ Loading FULL datasets into RAM (no chunking)...\\n\")\n",
    "\n",
    "# Load training data from chunks\n",
    "print(\"Loading training chunks...\")\n",
    "import glob\n",
    "train_data = []\n",
    "chunk_files = sorted(glob.glob('/kaggle/working/train_chunks/train_chunk_*.pkl'))\n",
    "for chunk_file in chunk_files:\n",
    "    with open(chunk_file, 'rb') as f:\n",
    "        chunk = pickle.load(f)\n",
    "        train_data.extend(chunk)\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(train_data):,} training samples\")\n",
    "\n",
    "# Load validation data\n",
    "with open(f'{DATA_DIR}/val_data.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "print(f\"‚úÖ Loaded {len(val_data):,} validation samples\")\n",
    "\n",
    "# Extract features and labels\n",
    "print(\"\\nExtracting features and labels...\")\n",
    "X_train = np.array([sample['features']['mel_spectrogram'] for sample in train_data], dtype=np.float32)\n",
    "y_train = np.array([sample['label']['threat_level'] for sample in train_data], dtype=np.int32)\n",
    "\n",
    "X_val = np.array([sample['features']['mel_spectrogram'] for sample in val_data], dtype=np.float32)\n",
    "y_val = np.array([sample['label']['threat_level'] for sample in val_data], dtype=np.int32)\n",
    "\n",
    "# Free memory\n",
    "del train_data, val_data\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nüìä Dataset shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "\n",
    "# Create tf.data.Dataset for optimized training\n",
    "BATCH_SIZE = 64  # Can try 128 if GPU memory allows\n",
    "\n",
    "print(f\"\\nüîÑ Creating optimized tf.data.Dataset pipelines...\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Preprocessing function with augmentation for custom CNN\n",
    "def preprocess_with_augmentation(x, y, augment=False):\n",
    "    # Add channel dimension: (128, 431) -> (128, 431, 1)\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    \n",
    "    # Data augmentation for training (reduces overfitting)\n",
    "    if augment:\n",
    "        # Random amplitude scaling (simulates volume variations)\n",
    "        scale = tf.random.uniform([], minval=0.8, maxval=1.2)\n",
    "        x = x * scale\n",
    "        \n",
    "        # Add slight Gaussian noise (simulates background noise)\n",
    "        noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=0.05)\n",
    "        x = x + noise\n",
    "        \n",
    "        # Random time shift (simulates different event timing)\n",
    "        shift = tf.random.uniform([], minval=-10, maxval=10, dtype=tf.int32)\n",
    "        x = tf.roll(x, shift=shift, axis=1)\n",
    "        \n",
    "        x = tf.clip_by_value(x, -3.0, 3.0)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# Wrapper functions for augmented vs clean preprocessing\n",
    "def preprocess_train(x, y):\n",
    "    return preprocess_with_augmentation(x, y, augment=True)\n",
    "\n",
    "def preprocess_val(x, y):\n",
    "    return preprocess_with_augmentation(x, y, augment=False)\n",
    "\n",
    "# Training dataset with augmentation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train), reshuffle_each_iteration=True)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.map(preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)  # Don't cache augmented data\n",
    "\n",
    "# Validation dataset (no augmentation)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.map(preprocess_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache()  # Cache in RAM for speed\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created with caching and prefetching!\")\n",
    "print(f\"  Training batches: {len(X_train) // BATCH_SIZE}\")\n",
    "print(f\"  Validation batches: {len(X_val) // BATCH_SIZE}\")\n",
    "print(f\"  üöÄ Ready for ultra-fast training with Custom CNN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d7958",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feea4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_names = ['BACKGROUND', 'THREAT_CONTEXT', 'THREAT']\n",
    "\n",
    "print(\"Computing class weights from training data...\")\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"\\nClass weights (for balanced training):\")\n",
    "for cls, weight in class_weight_dict.items():\n",
    "    count = np.sum(y_train == cls)\n",
    "    print(f\"  {class_names[cls]}: {weight:.3f} (n={count:,})\")\n",
    "\n",
    "print(f\"\\nCustom CNN input shape: (128, 431, 1)\")\n",
    "print(\"‚úÖ Ready for custom CNN training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be297dc",
   "metadata": {},
   "source": [
    "## 6. Build Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# IMPORTANT: Configure GPU settings BEFORE any TensorFlow operations\n",
    "# Enable GPU memory growth FIRST (before runtime initialization)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not set memory growth (already initialized): {e}\")\n",
    "\n",
    "# Now enable mixed precision for faster training\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "print(\"‚úÖ Mixed precision (float16) enabled for faster training\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "print(\"\\nüöÄ Building Custom CNN Model for Audio Classification...\")\n",
    "\n",
    "def build_custom_cnn(input_shape=(128, 431, 1), num_classes=3):\n",
    "    \"\"\"Build custom CNN model optimized for mel-spectrogram threat detection.\"\"\"\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Block 1: Extract low-level features\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Block 2: Mid-level features\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Block 3: High-level features\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Block 4: Deep features\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Classification head\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu',\n",
    "                    kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu',\n",
    "                    kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax', dtype='float32')  # float32 for stability\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_custom_cnn(input_shape=(128, 431, 1), num_classes=3)\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nüìä Model parameters: {model.count_params():,}\")\n",
    "print(\"üí° Custom CNN optimized for mel-spectrogram features\")\n",
    "\n",
    "# Compile with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model compiled!\")\n",
    "print(\"   4 conv blocks + strong regularization (L2, Dropout, BatchNorm)\")\n",
    "print(\"   Optimized for audio spectrogram classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e93477",
   "metadata": {},
   "source": [
    "## 7. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db53a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# Create model directory\n",
    "!mkdir -p /kaggle/working/models\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath='/kaggle/working/models/best_model_custom_cnn.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-8,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callback_list = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "print(\"‚úÖ Callbacks configured (weights-only checkpoint)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360438",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Custom CNN Training...\\n\")\n",
    "print(f\"üí° Batch size: {BATCH_SIZE}\")\n",
    "print(\"üíæ Full dataset cached in RAM for maximum speed\")\n",
    "print(\"üéØ Class weighting enabled for balanced training\")\n",
    "print(\"‚ö° Mixed precision + GPU acceleration\\n\")\n",
    "\n",
    "print(f\"üìä Dataset info:\")\n",
    "print(f\"  Training samples: {len(X_train):,}\")\n",
    "print(f\"  Validation samples: {len(X_val):,}\")\n",
    "print(f\"  Training batches per epoch: {len(X_train) // BATCH_SIZE}\")\n",
    "print(f\"  Validation batches per epoch: {len(X_val) // BATCH_SIZE}\\n\")\n",
    "\n",
    "print(\"‚è≥ Expected training time: 15-30 minutes with GPU...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callback_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3d1ad",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef58fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0].set_title('Model Loss (Custom CNN)', fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[1].set_title('Model Accuracy (Custom CNN)', fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d870f24",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üìä Evaluating on validation set...\\n\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_results = model.evaluate(val_dataset, verbose=1)\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(f\"  Loss: {val_results[0]:.4f}\")\n",
    "print(f\"  Accuracy: {val_results[1]:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_pred_proba = model.predict(val_dataset, verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.ylabel('True', fontweight='bold')\n",
    "plt.title('Confusion Matrix - Custom CNN - Validation Set', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation complete!\")\n",
    "test_results = val_results  # For compatibility with save cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0fdf2",
   "metadata": {},
   "source": [
    "## 11. Save Model and Export to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full model\n",
    "model.save('/kaggle/working/models/threat_detection_custom_cnn.keras')\n",
    "print(\"‚úÖ Full model saved\")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights('/kaggle/working/models/best_model_custom_cnn.weights.h5')\n",
    "print(\"‚úÖ Loaded best weights from checkpoint\")\n",
    "\n",
    "# Export to TensorFlow Lite\n",
    "print(\"\\nExporting to TensorFlow Lite...\")\n",
    "print(\"Converting mixed precision model to float32 for TFLite compatibility...\")\n",
    "\n",
    "# Create a float32 version of the model for TFLite conversion\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "model_f32 = build_custom_cnn(input_shape=(128, 431, 1), num_classes=3)\n",
    "model_f32.set_weights(model.get_weights())  # Copy weights from mixed precision model\n",
    "print(\"‚úÖ Created float32 model for conversion\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_f32)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]  # Quantize to float16 for smaller size\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('/kaggle/working/models/threat_detection_custom_cnn.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"‚úÖ TensorFlow Lite model: {len(tflite_model) / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Save model configuration\n",
    "model_config = {\n",
    "    'model_type': 'CustomCNN',\n",
    "    'val_accuracy': float(test_results[1]) if test_results else None,\n",
    "    'val_loss': float(test_results[0]) if test_results else None,\n",
    "    'class_names': class_names,\n",
    "    'input_shape': [128, 431, 1],\n",
    "    'preprocessing': config,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'total_parameters': int(model.count_params())\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/kaggle/working/models/model_config_custom_cnn.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model configuration saved\")\n",
    "\n",
    "# Upload to S3\n",
    "print(\"\\nUploading models to S3...\")\n",
    "!aws s3 cp /kaggle/working/models/threat_detection_custom_cnn.keras s3://{S3_BUCKET}/models/custom_cnn/\n",
    "!aws s3 cp /kaggle/working/models/best_model_custom_cnn.weights.h5 s3://{S3_BUCKET}/models/custom_cnn/\n",
    "!aws s3 cp /kaggle/working/models/threat_detection_custom_cnn.tflite s3://{S3_BUCKET}/models/custom_cnn/\n",
    "!aws s3 cp /kaggle/working/models/model_config_custom_cnn.json s3://{S3_BUCKET}/models/custom_cnn/\n",
    "\n",
    "print(\"\\n‚úÖ Models uploaded to S3!\")\n",
    "print(f\"   Location: s3://{S3_BUCKET}/models/custom_cnn/\")\n",
    "print(\"\\nüì¶ Files uploaded:\")\n",
    "print(\"  - threat_detection_custom_cnn.keras (full model)\")\n",
    "print(\"  - best_model_custom_cnn.weights.h5 (best weights)\")\n",
    "print(\"  - threat_detection_custom_cnn.tflite (edge deployment, optimized)\")\n",
    "print(\"  - model_config_custom_cnn.json (configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f42ae",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Custom CNN Training Complete! üéâ\n",
    "\n",
    "**Model Architecture:**\n",
    "- 4 convolutional blocks (32‚Üí64‚Üí128‚Üí256 filters)\n",
    "- Strong regularization: L2, Dropout, BatchNormalization\n",
    "- Optimized for mel-spectrogram features (128, 431, 1)\n",
    "- Data augmentation: amplitude scaling, noise, time shift\n",
    "\n",
    "**Model Comparison:**\n",
    "Compare this Custom CNN with MobileNetV2 transfer learning:\n",
    "- **Custom CNN**: Built from scratch, optimized for audio spectrograms\n",
    "- **MobileNetV2**: Pre-trained on ImageNet, adapted for audio\n",
    "\n",
    "**Next Steps:**\n",
    "1. Compare validation accuracy between Custom CNN and MobileNetV2\n",
    "2. Analyze confusion matrices for both models\n",
    "3. Choose best performing model for deployment\n",
    "4. Deploy TFLite model to Raspberry Pi"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
